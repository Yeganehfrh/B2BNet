{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaceTime Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 3\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "import pytorch_lightning as pl\n",
    "from src.b2bnet import B2BNetSpaceTimeModel, OtkaDataModule, OtkaTimeDimSplit\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment\n",
    "\n",
    "segment_size = 120 * 3  # 3sec\n",
    "batch_size = 256\n",
    "n_channels = 59\n",
    "n_features = 8\n",
    "hidden_size = 8\n",
    "max_epochs = 100\n",
    "\n",
    "datamodule = OtkaTimeDimSplit(segment_size=segment_size, batch_size=batch_size)\n",
    "\n",
    "model = B2BNetSpaceTimeModel(\n",
    "    n_channels=n_channels, n_features=n_features,\n",
    "    hidden_size=hidden_size, kernel_size=1, n_subjects=51)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=max_epochs,accelerator='cpu', log_every_n_steps=1, deterministic='warn')\n",
    "\n",
    "trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spatioTemporal test\n",
    "this code is used to first encode the spatial characteristics of EEG data (positional information) and then encode the temporal characteristics of EEG data (time information). The output of this code is a 3D matrix of size (number of channels, number of time points, number of spatial bins). This code is used to generate the data for the spatioTemporal decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 59, 120])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate random DATA\n",
    "input = torch.randn(1, 120, 59).permute(0, 2, 1)  # torch.Size([256, 360, 59])\n",
    "\n",
    "# model\n",
    "# encoder\n",
    "m = nn.Sequential(\n",
    "    nn.Conv1d(59, 30, 1, stride=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv1d(30, 15, 1, stride=1),\n",
    "    nn.ReLU(),\n",
    ")\n",
    "output = m(input)\n",
    "\n",
    "m = nn.LSTM(15, 10, batch_first=True)  # num_layers can be detemined by hyperparameter search\n",
    "output = m(output.permute(0, 2, 1))\n",
    "\n",
    "# decoder\n",
    "m = nn.LSTM(10, 15, batch_first=True)\n",
    "output = m(output[0])\n",
    "m = nn.Sequential(\n",
    "    nn.ConvTranspose1d(15, 30, 1, stride=1),\n",
    "    nn.ReLU(),\n",
    "    nn.ConvTranspose1d(30, 59, 1, stride=1),\n",
    ")\n",
    "output = m(output[0].permute(0, 2, 1))\n",
    "\n",
    "output.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "b2bnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
