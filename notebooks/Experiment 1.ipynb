{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "This notebook contains the code for the first experiment of the paper. In this experiment, we train a B2BNet model that first encodes the temporal dimensions of the EEG data and then its spatial dimensions. It does not include any B2B or classification heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 3\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "import pytorch_lightning as pl\n",
    "from src.b2bnet import B2BNetSpaceTimeModel, OtkaDataModule, OtkaTimeDimSplit\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "segment_size = 120 * 3 # 3sec\n",
    "batch_size = 256\n",
    "n_channels = 59\n",
    "space_embedding_dim = 8\n",
    "time_embedding_dim = 16\n",
    "max_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/b2bnet/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name     | Type                 | Params\n",
      "--------------------------------------------------\n",
      "0 | baseline | SpaceTimeAutoEncoder | 4.7 K \n",
      "--------------------------------------------------\n",
      "4.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.7 K     Total params\n",
      "0.019     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7fb097c93340369f710877a65d47c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/b2bnet/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/b2bnet/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc70188928d2446db6f356f8d3ce3eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f960e0f0da204e7488e1bbfaeca0b7fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/b2bnet/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:52: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "datamodule = OtkaTimeDimSplit(segment_size=segment_size, batch_size=batch_size, b2b_data=None,\n",
    "                              data_mode='crop')\n",
    "\n",
    "model = B2BNetSpaceTimeModel(\n",
    "    n_channels=n_channels, space_embedding_dim=space_embedding_dim,\n",
    "    time_embedding_dim=time_embedding_dim, kernel_size=1, n_subjects=52, classifier=False,\n",
    "    encoder_arch='autoencoder', b2b=None)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=max_epochs, accelerator='cpu', log_every_n_steps=1, deterministic='warn')\n",
    "\n",
    "trainer.fit(model, datamodule=datamodule)\n",
    "trainer.save_checkpoint(f'models/b2bnet_segment-{segment_size}.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1683, 16])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "\n",
    "model_ckpt = B2BNetSpaceTimeModel.load_from_checkpoint(\"lightning_logs/version_112/checkpoints/epoch=0-step=16.ckpt\")\n",
    "\n",
    "x, y, subject_ids, x_b2b, y_b2b, y_cls = datamodule.val_dataset[:]\n",
    "# embedding, y_hat, y_b2b_hat, embedding_b2b, y_cls_hat = model_ckpt(x, x_b2b)\n",
    "h, _ = model_ckpt.baseline(x)\n",
    "\n",
    "classifier_model = nn.Linear(h.shape[-1], 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "b2bnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
